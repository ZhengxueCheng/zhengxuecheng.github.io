---
---

@inproceedings{cheng2026tacobenchmarklosslesslossy,
    title={TaCo: A Benchmark for Lossless and Lossy Codecs of Heterogeneous Tactile Data}, 
    author={Zhengxue Cheng<sup>♯</sup> and Yan Zhao and Keyu Wang and Hengdi Zhang and Li Song},
    year={2026},
    booktitle = {International Conference on Learning Representations (ICLR)},
    url={https://arxiv.org/abs/2602.09893},
    preview={TaCo2026.png},
    selected={true}
}

@ARTICLE{iaste2025,
    author={Yan Zhao and Zhengxue Cheng<sup>♯</sup> and Jiangchuan Li and Donghui Feng and Qunshan Gu and Qi Wang and Guo Lu and Li Song<sup>♯</sup>},
    journal={IEEE Trans. on  Image Processing}, 
    title={Instance-Adaptive Spatial-Temporal Enhancement for Efficient Video Compression}, 
    year={2025},
    volume={34},
    number={},
    pages={5776-5791},
    keywords={Videos;Adaptation models;Spatiotemporal phenomena;Overfitting;Decoding;Spatial resolution;Transformers;Video compression;Image coding;Correlation;Video compression;spatial-temporal enhancement;instance-adaptive overfitting;low-rank adaption},
    doi={10.1109/TIP.2025.3602648},
    preview={iaste2025.png},
    selected={true}
}


@inproceedings{Feng2025LALIC,
    author    = {Donghui Feng<sup>*</sup> and Zhengxue Cheng<sup>*</sup> and Shen Wang and Ronghua Wu and Hongwei Hu and Guo Lu and Li Song<sup>♯</sup>},
    title     = {Linear Attention Modeling for Learned Image Compression},
    booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern	Recognition (CVPR)},
    year      = {2025},
    month={June},
    pages     = {1-10},
    url       = {https://arxiv.org/abs/2502.05741},
    selected={true},
    preview={lalic2025.png}
}

@inproceedings{10.1145/3746027.3755136,
    author = {Ruiyan Wang and Zhengxue Cheng<sup>♯</sup> and Zonghao Lin and Jun Ling and Yuzhou Liu and Yanru An and Rong Xie and Li Song<sup>♯</sup>},
    title = {SemanticGarment: Semantic-Controlled Generation and Editing of 3D Gaussian Garments},
    year = {2025},
    isbn = {9798400720352},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3746027.3755136},
    doi = {10.1145/3746027.3755136},
    booktitle = {Proceedings of the 33rd ACM International Conference on Multimedia},
    pages = {9793–9802},
    numpages = {10},
    keywords = {3d gaussian splatting, 3d multimodal generation, animation, clothing generation and editing},
    location = {Dublin, Ireland},
    series = {MM '25}
}

@inproceedings{10.1145/3746027.3758232,
    author = {Bate Li and Houqiang Zhong and Zhengue Cheng<sup>♯</sup> and Qiang Hu and Qiang Wang and Li Song<sup>♯</sup> and Wenjun Zhang<sup>♯</sup>},
    title = {MultiEgo: A Multi-View Egocentric Video Dataset for 4D Scene Reconstruction},
    year = {2025},
    isbn = {9798400720352},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3746027.3758232},
    doi = {10.1145/3746027.3758232},
    booktitle = {Proceedings of the 33rd ACM International Conference on Multimedia},
    pages = {12882–12889},
    numpages = {8},
    keywords = {dynamic scene, egocentric video, free-viewpoint video},
    location = {Dublin, Ireland},
    series = {MM '25}
}

@inproceedings{10.1145/3746027.3758217,
    author = {Ruiyan Wang and Lin Zuo and Zonghao Lin and Qiang Wang and Zhengxue Cheng<sup>♯</sup> and Rong Xie and Jun Ling<sup>♯</sup> and Li Song<sup>♯</sup>},
    title = {PA-HOI: A Physics-Aware Human and Object Interaction Dataset},
    year = {2025},
    isbn = {9798400720352},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3746027.3758217},
    doi = {10.1145/3746027.3758217},
    booktitle = {Proceedings of the 33rd ACM International Conference on Multimedia},
    pages = {12769–12775},
    numpages = {7},
    keywords = {human-object interaction, physical attribute-aware, text-driven hoi synthesis},
    location = {Dublin, Ireland},
    series = {MM '25}
}

@inproceedings{l3tc2025,
    author = {Junxuan Zhang<sup>*</sup> and Zhengxue Cheng<sup>*♯</sup> and Yan Zhao and Shihao Wang and Dajiang Zhou and Guo Lu and Li Song},
    title = {L3TC: leveraging RWKV for learned lossless low-complexity text compression},
    year = {2025},
    isbn = {978-1-57735-897-8},
    publisher = {AAAI Press},
    url = {https://doi.org/10.1609/aaai.v39i12.33446},
    doi = {10.1609/aaai.v39i12.33446},
    booktitle = {Proceedings of the Thirty-Ninth AAAI Conference on Artificial Intelligence},
    articleno = {1473},
    numpages = {9},
    series = {AAAI'25/IAAI'25/EAAI'25},
    preview={l3tc2025.png},
    selected={true}
}


@ARTICLE{omniscalesr2025,
    author={Xinning Chai and Zhengxue Cheng<sup>♯</sup> and Yuhong Zhang and Hengsheng Zhang and Yingsheng Qin and Yucai Yang and Rong Xie and Li Song<sup>♯</sup>},
    journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
    title={OmniScaleSR: Unleashing Scale-Controlled Diffusion Prior for Faithful and Realistic Arbitrary-Scale Image Super-Resolution}, 
    year={2025},
    volume={},
    number={},
    pages={1-1},
    keywords={Superresolution;Diffusion models;Noise reduction;Adaptation models;Image reconstruction;Feature extraction;Transformers;Degradation;Videos;Text to image;Image super-resolution;diffusion models;scale-controlled generation;high-magnification reconstruction;arbitrary-scale super-resolution},
    doi={10.1109/TCSVT.2025.3642578},
    preview={omniscalesr.png},
    selected={true}
}


@ARTICLE{diffrestorer2025,
    author={Yuhong Zhang and Hengsheng Zhang and Xinning Chai and Zhengxue Cheng<sup>♯</sup> and Rong Xie and Li Song<sup>♯</sup> and Wenjun Zhang},
    journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
    title={Diff-Restorer: Unleashing Visual Prompts for Diffusion-based Universal Image Restoration}, 
    year={2025},
    volume={},
    number={},
    pages={1-1},
    keywords={Image restoration;Degradation;Visualization;Diffusion models;Semantics;Adaptation models;Multitasking;Decoding;Image synthesis;Training;Image restoration;universal image restoration;diffusion models;visual prompt;CLIP},
    doi={10.1109/TCSVT.2025.3629686},
    preview={diffrestorer2025.png},
    selected={true}
}


@ARTICLE{sspir2025,
    author={Yuhong Zhang and Hengsheng Zhang and Zhengxue Cheng<sup>♯</sup> and Rong Xie and Li Song<sup>♯</sup> and Wenjun Zhang},
    journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
    title={SSP-IR: Semantic and Structure Priors for Diffusion-Based Realistic Image Restoration}, 
    year={2025},
    volume={35},
    number={7},
    pages={6259-6272},
    keywords={Image restoration;Semantics;Degradation;Training;Diffusion models;Accuracy;Visualization;Noise reduction;Data mining;Superresolution;Image restoration;diffusion models;realistic super-resolution;MLLM},
    doi={10.1109/TCSVT.2025.3538772},
    preview={sspir2025.png},
    selected={true}
}



@misc{cheng2025omnivtlavisiontactilelanguageactionmodelsemanticaligned,
    title={OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing}, 
    author={Zhengxue Cheng and Yiqian Zhang and Wenkang Zhang and Haoyu Li and Keyu Wang and Li Song and Hengdi Zhang},
    year={2025},
    eprint={2508.08706},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    preview={vtla2025.png},
    selected={true},
    url={https://arxiv.org/abs/2508.08706} 
}


@inproceedings{rateawarenerf,
    author = {Zhiyu Zhang<sup>*</sup> and Guo Lu<sup>*</sup> and Huanxiong Liang and Zhengxue Cheng<sup>♯</sup> and Anni Tang and Li Song<sup>♯</sup>},
    title = {Rate-aware Compression for NeRF-based Volumetric Video},
    year = {2024},
    isbn = {9798400706868},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3664647.3680970},
    doi = {10.1145/3664647.3680970},
    booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
    pages = {3974–3983},
    numpages = {10},
    keywords = {compression, nerf, rate estimation, volumetric video},
    location = {Melbourne VIC, Australia},
    series = {MM '24},
    selected={true},
    preview={nerf2024.png}
}


@inproceedings{cheng2020cvpr,
    title={Learned Image Compression with Discretized Gaussian Mixture Likelihoods and Attention Modules},
    author={Cheng, Zhengxue and Sun, Heming and Takeuchi, Masaru and Katto, Jiro},
    journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    abstract={Image compression is a fundamental research field and many well-known compression standards have been developed for many decades. Recently, learned compression methods exhibit a fast development trend with promising results. However, there is still a performance gap between learned compression algorithms and reigning compression standards, especially in terms of widely used PSNR metric. In this paper, we explore the remaining redundancy of recent learned compression algorithms. We have found accurate entropy models for rate estimation largely affect the optimization of network parameters and thus affect the rate-distortion performance. Therefore, in this paper, we propose to use discretized Gaussian Mixture Likelihoods to parameterize the distributions of latent codes, which can achieve a more accurate and flexible entropy model. Besides, we take advantage of recent attention modules and incorporate them into network architecture to enhance the performance. Experimental results demonstrate our proposed method achieves a state-of-the-art performance compared to existing learned compression methods on both Kodak and high-resolution datasets. To our knowledge our approach is the first work to achieve comparable performance with latest compression standard Versatile Video Coding (VVC) regarding PSNR. More importantly, our approach generates more visually pleasant results when optimized by MS-SSIM. },
    year={2020},
    month={June},
    pdf={https://arxiv.org/abs/2001.01568},
    url={https://github.com/ZhengxueCheng/Learned-Image-Compression-with-GMM-and-Attention},
    selected={true},
    preview={cvpr2020.png}
}

@ARTICLE{cheng2020tmm,
    author={Cheng, Zhengxue and Sun, Heming and Takeuchi, Masaru and Katto, Jiro},
    journal={IEEE Transactions on Multimedia}, 
    title={Energy Compaction-Based Image Compression Using Convolutional AutoEncoder}, 
    abstract={Image compression has been an important research topic for many decades. Recently, deep learning has achieved great success in many computer vision tasks, and its use in image compression has gradually been increasing. In this paper, we present an energy compaction-based image compression architecture using a convolutional autoencoder (CAE) to achieve high coding efficiency. Our main contributions include three aspects: 1) we propose a CAE architecture for image compression by decomposing it into several down(up)sampling operations; 2) for our CAE architecture, we offer a mathematical analysis on the energy compaction property and we are the first work to propose a normalized coding gain metric in neural networks, which can act as a measurement of compression capability; 3) based on the coding gain metric, we propose an energy compaction-based bit allocation method, which adds a regularizer to the loss function during the training stage to help the CAE maximize the coding gain and achieve high compression efficiency. The experimental results demonstrate our proposed method outperforms BPG (HEVC-intra), in terms of the MS-SSIM quality metric. Additionally, we achieve better performance in comparison with existing bit allocation methods, and provide higher coding efficiency compared with state-of-the-art learning compression methods at high bit rates.},
    year={2020},
    volume={22},
    number={4},
    pages={860-873},
    keywords={Image coding;Bit rate;Convolutional codes;Quantization (signal);Image reconstruction;Compaction;Neural networks;Image compression;convolutional autoencoder;optimum bit allocation;energy compaction},
    doi={10.1109/TMM.2019.2938345}
}

@INPROCEEDINGS{cheng2020icassp,
  author={Cheng, Zhengxue and Sun, Heming and Takeuchi, Masaru and Katto, Jiro},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Learned Lossless Image Compression with A Hyperprior and Discretized Gaussian Mixture Likelihoods}, 
  year={2020},
  volume={},
  number={},
  pages={2158-2162},
  keywords={Training;Deep learning;Adaptation models;Image coding;Transform coding;Task analysis;Context modeling;Lossless Image Compression;Deep Learning;HyperPrior;Gaussian Mixture Model},
  doi={10.1109/ICASSP40776.2020.9053413}
}




@INPROCEEDINGS{cheng2019cvpr,
    author={Cheng, Zhengxue and Sun, Heming and Takeuchi, Masaru and Katto, Jiro},
    booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
    title={Learning Image and Video Compression Through Spatial-Temporal Energy Compaction}, 
    year={2019},
    volume={},
    number={},
    pages={10063-10072},
    keywords={Measurement;Interpolation;Image coding;Transform coding;Video compression;Entropy;Compaction;Pattern recognition;Decoding;Standards;Image and Video Synthesis;Deep Learning ; Representation Learning; Video Analytics; Vision Applications and Systems},
    doi={10.1109/CVPR.2019.01031}
}